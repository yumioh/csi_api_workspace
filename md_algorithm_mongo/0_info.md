# MD기반 근로자 위험도 예측 알고리즘 (MongoDB version)


## 1. MD알고리즘이란?
- 목적: 다차원 데이터 공간에서 각 근로자의 데이터 포인트를 사고 발생 집단과 비교하여 근로자의 사고 위험도를 정량적으로 평가. 
<br/> Mahalanobis Distance를 사용하여 다변량 데이터의 중심(평균)과의 거리를 측정하고, 변수들 간의 상관관계를 고려하여 
<br/> 각 데이터 포인트의 이상치 정도를 평가.

- 위험 예측: 근로자의 특성(공사규모, 사고발생시간, 나이, 경력)을 통합적으로 고려하여 사고 위험도를 예측. 
<br/> 이를 통해 특정 근로자의 위험도가 높은지를 판단할 수 있음. 

## 데이터 정의 (사고 VS 비사고 데이터)
 - 사고 데이터 : KOSHA(산업안전보건공단) 52,872건
 - 비사고 데이터 : GH(보건환경연구원) 64743건

## MongoDB 정의
 - database명 : accident_data
 - collection명 : accidents(사고데이터), non_accidents(비사고데이터)

## 데이터 전처리 
 1. 사고데이터(KOSHA 데이터)  <br/>
 
|공통컬럼명|KOSHA 컬럼명|변경내역|
  |------|---|---|
  |나이|출생년도|별도 계산필요|
  |발생일자|동일|yyyy-mm-dd 형태로 변환 필요 |
  |발생시간|동일||
  |근무경력|근무일수||
  |공사규모|동일| |
  |발생요일|없음|발생일자에서 발생요일 추출|
  |발생월|없음|발생일자에서 발생월 추출|

  
  2. 비사고데이터(GH, 보령 데이터) <br/>
  
  |공통컬럼명|KOSHA 컬럼명|변경내역|
  |------|---|---|
  |나이|생년월일|별도 계산필요|
  |발생일자|출력일자| yyyy-mm-dd 형태로 변환 필요 |
  |발생시간|없음| 일괄적으로 8시 추가|
  |근무경력|건설업근무경력||
  |공사규모|현장규모| |
  |발생요일|출역일자|발생일자에서 발생요일 추출|
  |발생월|없음|발생일자에서 발생월 추출|

## 다변량 분석을 통한 변수 선별
  **1. Random Forest** <br/> 
      &nbsp; &nbsp; - Random Forest는 수많은 의사 결정 트리가 모여서 생성. 전체 Feature 중 랜덤으로 일부 Feature만 선택하여 하나의 결정 트리를 만들고, <br/> 
      &nbsp; &nbsp; &nbsp; 또 전체 Feature 중 램덤으로 일부 Feature를 선택해 또 다른 결정 트리를 만들며, 여러 개의 결정 트리를 만드는 방식으로 구성. <br/> &nbsp; &nbsp; &nbsp;  의사 결정 트리마다 하나의 예측값을 내놓음. <br/> 
    &nbsp; &nbsp; - 여러 결정 트리들이 내린 예측 값들 중, 가장 많이 나온 값을 최종 예측값으로 정함. 여러 가지 결과를 합치는 방식을 앙상블 <br/>
    &nbsp; &nbsp; &nbsp; 즉, 하나의 거대한 결정 트리를 만드는 것이 아니라 여러 개의 작은 결정 트리를 만드는 것 <br/>
    &nbsp; &nbsp; - 여러 개의 작은 결정 트리가 예측한 값들 중. 가장 많이 등장한 값 또는 평균값을 최종 예측값으로 정함 <br/>
  <br/>

  **2. XGBoost** <br/> 
    &nbsp; &nbsp; - 여러 개의 약한 **결정 트리(Decision Tree)**를 조합하여 강력한 예측 모델을 만드는 부스팅 앙상블 기법 중 하나 <br/>
    &nbsp; &nbsp; - 약한 예측 모델(약한 학습기)의 학습 오류에 가중치를 두고, 순차적으로 다음 학습 모델에 반영하여 예측 성능을 점진적으로 개선 <br/>
    &nbsp; &nbsp; - 데이터를 일정 간격으로 나누어 **최적의 분할(split)**을 찾는 과정을 병렬 처리하여 학습 속도를 크게 향상 <br/>

    분할방식
    
     * exact : 모든 피처의 모든 데이터값을 분할 후보군으로 고려하는 기본 방식(바닐라 Gradient Boosting).  가장 정확하지만 데이터가 많을수록 시간 많이 소요
     * approx : 데이터를 **분위수(quantile)**로 나누어 각 그룹별로 최적의 분할 포인트를 찾는 방식. exact보다 효율적이며, 대규모 데이터에서도 적합
     * hist : 데이터를 **히스토그램(bin)**으로 구분하여 최적의 분할 포인트를 찾는 방식. 메모리 사용량이 적음
     * gpu_hist : hist 방식의 GPU 구현 버전으로, GPU를 활용해 학습 속도를 더욱 높임

 <br/>
 
 - boxplot 분석을 통해 두집단(사고발생집단과 사고 비발생 집단)간에 차이가 크게 나타난 변수들을 선별
   <br/> => 선별된 변수는 공사규모, 사고발생시간, 근로자 나이, 근로자 경력 등 
 
## MD계산
 - 공분산 행렬이란? 
        - 데이터 세트의 변수들 사이의 공분산 값을 정리한 정방 행렬(square matrix)로, 데이터의 변수 개수에 <br/> 따라 행렬의 크기가 결정 <br/>
        - 행렬의 크기 : n x n (n: 변수의 개수) <br/>
        - 항목이 6개면 36개의 특성을 가짐. => 각 요소는 두 특성간의 공분산 값을 나타내며, 1296개의 공분산 값을 포함 <br/>
        - 데이터 축소나 변환 : 데이터를 변환하거 축소하는 과정에서 특성의 수가 줄어 들 수가 있음 <br/>

## 척도 적용 
 - 데이터가 없어 랜덤 데이터 넣기 

## 정규화 적용 (minmaxscaling)

## 시각화 
- MD -> logMD
- MD -> normalize
- MD -> log MD -> normalize

## 위험도 예측


